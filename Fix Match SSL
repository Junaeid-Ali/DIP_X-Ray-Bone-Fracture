{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12499976,"sourceType":"datasetVersion","datasetId":7889015}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/junaeidali123/x-ray-bone-fracture-ssl-fix-match?scriptVersionId=256309140\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"import json\nfrom sklearn.metrics import precision_recall_fscore_support\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\n\n\nimport os\nimport random\nimport torch\nimport numpy as np\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import Dataset, DataLoader, Subset\nimport timm\nimport torch.nn.functional as F\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed_all(SEED)\n\ndata_dir = \"/kaggle/input/x-ray-bone-fracture-dataset/X-ray Bone Fracture Dataset Comprehensive Imaging for Fracture Classification and Medical Research/Bone -Fracture/Bone Fracture/Orginal\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T18:38:46.773604Z","iopub.execute_input":"2025-08-13T18:38:46.773893Z","iopub.status.idle":"2025-08-13T18:38:52.140445Z","shell.execute_reply.started":"2025-08-13T18:38:46.773868Z","shell.execute_reply":"2025-08-13T18:38:52.139605Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Load Dataset**","metadata":{}},{"cell_type":"code","source":"data_dir = \"/kaggle/input/x-ray-bone-fracture-dataset/X-ray Bone Fracture Dataset Comprehensive Imaging for Fracture Classification and Medical Research/Bone -Fracture/Bone Fracture/Orginal\"\n\nfrom torchvision import datasets\nfull_dataset = datasets.ImageFolder(root=data_dir)\ndataset_size = len(full_dataset)\ntargets = full_dataset.targets  # list of labels\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T18:38:52.141703Z","iopub.execute_input":"2025-08-13T18:38:52.141989Z","iopub.status.idle":"2025-08-13T18:38:53.995284Z","shell.execute_reply.started":"2025-08-13T18:38:52.141968Z","shell.execute_reply":"2025-08-13T18:38:53.994428Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Split the dataset (Train, Test, Validation)","metadata":{}},{"cell_type":"code","source":"indices = list(range(dataset_size))\n\ntrain_indices, temp_indices = train_test_split(\n    indices, test_size=0.2, stratify=[targets[i] for i in indices], random_state=SEED)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T18:38:53.996235Z","iopub.execute_input":"2025-08-13T18:38:53.996469Z","iopub.status.idle":"2025-08-13T18:38:54.004543Z","shell.execute_reply.started":"2025-08-13T18:38:53.996451Z","shell.execute_reply":"2025-08-13T18:38:54.003837Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# indices = list(range(dataset_size))\n\n# train_indices, temp_indices = train_test_split(\n#     indices, test_size=0.2, stratify=[targets[i] for i in indices], random_state=SEED)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T18:38:54.006574Z","iopub.execute_input":"2025-08-13T18:38:54.00732Z","iopub.status.idle":"2025-08-13T18:38:54.021029Z","shell.execute_reply.started":"2025-08-13T18:38:54.007297Z","shell.execute_reply":"2025-08-13T18:38:54.020226Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"val_indices, test_indices = train_test_split(\n    temp_indices, test_size=0.5, stratify=[targets[i] for i in temp_indices], random_state=SEED)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T18:38:54.021664Z","iopub.execute_input":"2025-08-13T18:38:54.021853Z","iopub.status.idle":"2025-08-13T18:38:54.039855Z","shell.execute_reply.started":"2025-08-13T18:38:54.021838Z","shell.execute_reply":"2025-08-13T18:38:54.039045Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Split Train (Label, Unlabel)","metadata":{}},{"cell_type":"code","source":"train_targets = [targets[i] for i in train_indices]\nnum_train = len(train_indices)\nnum_labeled = int(0.4* num_train)\n\nrandom.seed(SEED)\nshuffled_train_indices = train_indices.copy()\nrandom.shuffle(shuffled_train_indices)\n\nlabeled_indices = shuffled_train_indices[:num_labeled]\nunlabeled_indices = shuffled_train_indices[num_labeled:]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T18:38:54.040855Z","iopub.execute_input":"2025-08-13T18:38:54.041203Z","iopub.status.idle":"2025-08-13T18:38:54.057452Z","shell.execute_reply.started":"2025-08-13T18:38:54.041175Z","shell.execute_reply":"2025-08-13T18:38:54.056694Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"splits = {\n    \"train\": train_indices,\n    \"val\": val_indices,\n    \"test\": test_indices,\n    \"train_labeled\": labeled_indices,\n    \"train_unlabeled\": unlabeled_indices\n}\n\noutput_path = \"./splits.json\"  # current notebook directory\nwith open(output_path, \"w\") as f:\n    json.dump(splits, f)\n\nprint(f\"Saved splits.json with {len(train_indices)} train, {len(val_indices)} val, {len(test_indices)} test samples.\")\nprint(f\"Labeled train: {len(labeled_indices)} samples, Unlabeled train: {len(unlabeled_indices)} samples\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T18:38:54.05815Z","iopub.execute_input":"2025-08-13T18:38:54.05836Z","iopub.status.idle":"2025-08-13T18:38:54.080848Z","shell.execute_reply.started":"2025-08-13T18:38:54.058344Z","shell.execute_reply":"2025-08-13T18:38:54.080051Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Transformation","metadata":{}},{"cell_type":"code","source":"# Base transform for validation and labeled data\nbase_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225])\n])\n\n# Weak augmentation (like base but with random flip)\nweak_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.RandomRotation(15),                \n    transforms.ColorJitter(brightness=0.3,     \n                           contrast=0.3,\n                           saturation=0.3,\n                           hue=0.1),\n    \n   \n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225])\n    \n])\n\n# Strong augmentation (RandAugment or similar)\nfrom torchvision.transforms import RandAugment\n\nstrong_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    RandAugment(), \n    transforms.RandomRotation(15),               \n    transforms.ColorJitter(brightness=0.3,       \n                           contrast=0.3,\n                           saturation=0.3,\n                           hue=0.1),\n   \n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225])\n                             \n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T18:38:54.081431Z","iopub.execute_input":"2025-08-13T18:38:54.081624Z","iopub.status.idle":"2025-08-13T18:38:54.097184Z","shell.execute_reply.started":"2025-08-13T18:38:54.081608Z","shell.execute_reply":"2025-08-13T18:38:54.096469Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Create Subsets from full dataset","metadata":{}},{"cell_type":"code","source":"train_subset = Subset(full_dataset, train_indices)\nval_subset = Subset(full_dataset, val_indices)\ntest_subset = Subset(full_dataset, test_indices)\n\nlabeled_subset = Subset(full_dataset, labeled_indices)\nunlabeled_subset = Subset(full_dataset, unlabeled_indices)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T18:38:54.097939Z","iopub.execute_input":"2025-08-13T18:38:54.098212Z","iopub.status.idle":"2025-08-13T18:38:54.115417Z","shell.execute_reply.started":"2025-08-13T18:38:54.098195Z","shell.execute_reply":"2025-08-13T18:38:54.114815Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Custom Dataset","metadata":{}},{"cell_type":"code","source":"class LabeledDataset(Dataset):\n    def __init__(self, subset, transform=None):\n        self.subset = subset\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.subset)\n    \n    def __getitem__(self, idx):\n        img, label = self.subset[idx]\n        if self.transform:\n            img = self.transform(img)\n        return img, label\n\nclass UnlabeledDataset(Dataset):\n    def __init__(self, subset, weak_transform=None, strong_transform=None):\n        self.subset = subset\n        self.weak_transform = weak_transform\n        self.strong_transform = strong_transform\n    \n    def __len__(self):\n        return len(self.subset)\n    \n    def __getitem__(self, idx):\n        img, _ = self.subset[idx]\n        weak_img = self.weak_transform(img) if self.weak_transform else img\n        strong_img = self.strong_transform(img) if self.strong_transform else img\n        return weak_img, strong_img\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T18:38:54.118144Z","iopub.execute_input":"2025-08-13T18:38:54.118405Z","iopub.status.idle":"2025-08-13T18:38:54.135021Z","shell.execute_reply.started":"2025-08-13T18:38:54.118379Z","shell.execute_reply":"2025-08-13T18:38:54.134216Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Instantiate Datasets with Transforms","metadata":{}},{"cell_type":"code","source":"labeled_dataset = LabeledDataset(labeled_subset, transform=base_transform)\nunlabeled_dataset = UnlabeledDataset(unlabeled_subset, weak_transform=weak_transform, strong_transform=strong_transform)\nval_dataset = LabeledDataset(val_subset, transform=base_transform)\ntest_dataset = LabeledDataset(test_subset, transform=base_transform)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T18:38:54.13575Z","iopub.execute_input":"2025-08-13T18:38:54.135926Z","iopub.status.idle":"2025-08-13T18:38:54.160209Z","shell.execute_reply.started":"2025-08-13T18:38:54.135912Z","shell.execute_reply":"2025-08-13T18:38:54.159204Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Loader","metadata":{}},{"cell_type":"code","source":"labeled_loader = DataLoader(labeled_dataset, batch_size=32, shuffle=True, drop_last=True)\nunlabeled_loader = DataLoader(unlabeled_dataset, batch_size=32, shuffle=True, drop_last=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T18:38:54.160853Z","iopub.execute_input":"2025-08-13T18:38:54.161213Z","iopub.status.idle":"2025-08-13T18:38:54.180215Z","shell.execute_reply.started":"2025-08-13T18:38:54.161192Z","shell.execute_reply":"2025-08-13T18:38:54.179549Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Define Model, Freeze Backbone, Optimizer","metadata":{}},{"cell_type":"code","source":"num_classes = len(full_dataset.classes)\nmodel = timm.create_model('efficientnetv2_s', pretrained=False, num_classes=num_classes)\nmodel = model.to(device)\n\ndef freeze_backbone(model, freeze=True):\n    total_params = len(list(model.parameters()))\n    freeze_count = int(0.25 * total_params)\n    for i, param in enumerate(model.parameters()):\n        param.requires_grad = not (freeze and i < freeze_count)\n\nfreeze_backbone(model, freeze=True)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T18:38:54.181031Z","iopub.execute_input":"2025-08-13T18:38:54.181303Z","iopub.status.idle":"2025-08-13T18:38:54.783092Z","shell.execute_reply.started":"2025-08-13T18:38:54.181287Z","shell.execute_reply":"2025-08-13T18:38:54.782252Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#  Validation Function","metadata":{}},{"cell_type":"code","source":"def validate(model, dataloader):\n    model.eval()\n    all_preds, all_labels = [], []\n    with torch.no_grad():\n        for imgs, labels in dataloader:\n            imgs, labels = imgs.to(device), labels.to(device)\n            outputs = model(imgs)\n            preds = outputs.argmax(dim=1)\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n    acc = accuracy_score(all_labels, all_preds)\n    prec, rec, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted', zero_division=0)\n    return acc, prec, rec, f1\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T18:38:54.783825Z","iopub.execute_input":"2025-08-13T18:38:54.784439Z","iopub.status.idle":"2025-08-13T18:38:54.789521Z","shell.execute_reply.started":"2025-08-13T18:38:54.784418Z","shell.execute_reply":"2025-08-13T18:38:54.7888Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training Loop(Fix Match)","metadata":{}},{"cell_type":"code","source":"num_epochs = 75\nfreeze_epochs = 5\ntau = 0.9\nlambda_u = 1.0\n\ntrain_sup_losses = []\ntrain_unsup_losses = []\nval_accuracies = []\nval_precisions = []\nval_recalls = []\nval_f1s = []\n\nfor epoch in range(1, num_epochs+1):\n    model.train()\n    \n    if epoch == freeze_epochs + 1:\n        freeze_backbone(model, freeze=False)\n        print(f\"Epoch {epoch}: Unfroze backbone layers\")\n    \n    sup_loss_running = 0.0\n    unsup_loss_running = 0.0\n    batches = 0\n    \n    for (x_labeled, y_labeled), (x_unl_weak, x_unl_strong) in zip(labeled_loader, unlabeled_loader):\n        x_labeled, y_labeled = x_labeled.to(device), y_labeled.to(device)\n        x_unl_weak, x_unl_strong = x_unl_weak.to(device), x_unl_strong.to(device)\n        \n        optimizer.zero_grad()\n        \n        # Supervised loss\n        logits_labeled = model(x_labeled)\n        loss_sup = F.cross_entropy(logits_labeled, y_labeled)\n        \n        # Pseudo-label generation on weak augmented unlabeled images\n        with torch.no_grad():\n            preds_unl_weak = F.softmax(model(x_unl_weak), dim=1)\n            max_probs, pseudo_labels = torch.max(preds_unl_weak, dim=1)\n            mask = (max_probs >= tau).float()\n        \n        # Unsupervised loss on strong augmented images\n        logits_unl_strong = model(x_unl_strong)\n        loss_unsup_all = F.cross_entropy(logits_unl_strong, pseudo_labels, reduction='none')\n        loss_unsup = (loss_unsup_all * mask).mean()\n        \n        loss = loss_sup + lambda_u * loss_unsup\n        loss.backward()\n        optimizer.step()\n        \n        sup_loss_running += loss_sup.item()\n        unsup_loss_running += loss_unsup.item()\n        batches += 1\n    \n    avg_sup_loss = sup_loss_running / batches\n    avg_unsup_loss = unsup_loss_running / batches\n    \n    train_sup_losses.append(avg_sup_loss)\n    train_unsup_losses.append(avg_unsup_loss)\n    \n    val_acc, val_prec, val_rec, val_f1 = validate(model, val_loader)\n    val_accuracies.append(val_acc)\n    val_precisions.append(val_prec)\n    val_recalls.append(val_rec)\n    val_f1s.append(val_f1)\n    \n    print(f\"Epoch {epoch}/{num_epochs} | Sup Loss: {avg_sup_loss:.4f} | Unsup Loss: {avg_unsup_loss:.4f}\")\n    print(f\"Val Acc: {val_acc:.4f} | Val Prec: {val_prec:.4f} | Val Rec: {val_rec:.4f} | Val F1: {val_f1:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T18:38:54.790506Z","iopub.execute_input":"2025-08-13T18:38:54.790813Z","iopub.status.idle":"2025-08-13T20:03:36.444801Z","shell.execute_reply.started":"2025-08-13T18:38:54.790787Z","shell.execute_reply":"2025-08-13T20:03:36.443905Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Plot Training Curves","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(16,5))\n\nplt.subplot(1,2,1)\nplt.plot(train_sup_losses, label='Supervised Loss')\nplt.plot(train_unsup_losses, label='Unsupervised Loss')\nplt.title(\"Training Losses\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend()\n\nplt.subplot(1,2,2)\nplt.plot(val_accuracies, label='Validation Accuracy')\nplt.plot(val_precisions, label='Validation Precision')\nplt.plot(val_recalls, label='Validation Recall')\nplt.plot(val_f1s, label='Validation F1')\nplt.title(\"Validation Metrics\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Score\")\nplt.legend()\n\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T20:03:36.445687Z","iopub.execute_input":"2025-08-13T20:03:36.445975Z","iopub.status.idle":"2025-08-13T20:03:37.087844Z","shell.execute_reply.started":"2025-08-13T20:03:36.445953Z","shell.execute_reply":"2025-08-13T20:03:37.087129Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Classification Report","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.metrics import classification_report\n\ndef display_classification_report(model, dataloader, device, target_names=None):\n    model.eval()\n    all_preds = []\n    all_labels = []\n    with torch.no_grad():\n        for images, labels in dataloader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            preds = torch.argmax(outputs, dim=1)\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n    \n    report_dict = classification_report(all_labels, all_preds, target_names=target_names, zero_division=0, output_dict=True)\n    df_report = pd.DataFrame(report_dict).transpose()\n    \n    print(df_report)   # Text print\n    display(df_report) # Nice table display (in Jupyter notebooks)\n    return df_report\n\n# Usage:\nclass_names = full_dataset.classes\ndisplay_classification_report(model, val_loader, device, target_names=class_names)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T20:03:37.088792Z","iopub.execute_input":"2025-08-13T20:03:37.089026Z","iopub.status.idle":"2025-08-13T20:03:42.341364Z","shell.execute_reply.started":"2025-08-13T20:03:37.089009Z","shell.execute_reply":"2025-08-13T20:03:42.340491Z"}},"outputs":[],"execution_count":null}]}